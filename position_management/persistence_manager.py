#!/usr/bin/env python3
"""
üíæ PERSISTENCE MANAGER - Gesti√≥n de Persistencia y Cache V3.0
============================================================

Componente responsable de la sincronizaci√≥n bidireccional entre modelos
in-memory y base de datos, con cache inteligente y transacciones ACID.

üéØ FUNCIONALIDADES:
1. Sincronizaci√≥n autom√°tica entre memoria y base de datos
2. Cache inteligente con invalidaci√≥n autom√°tica
3. Transacciones ACID para operaciones cr√≠ticas
4. Backup y recovery de datos de posiciones
5. Optimizaci√≥n de consultas con batching
6. Detecci√≥n y resoluci√≥n de conflictos de datos

üîß ARQUITECTURA:
- Write-Through Cache: Escrituras van directamente a DB y cache
- Read-Through Cache: Lecturas cargan desde DB si no est√° en cache
- Transaction Manager: Manejo de transacciones complejas
- Conflict Resolver: Resoluci√≥n autom√°tica de conflictos
- Backup Manager: Snapshots peri√≥dicos de datos cr√≠ticos

üéØ PATRONES IMPLEMENTADOS:
- Unit of Work: Agrupa operaciones en transacciones
- Repository: Abstrae acceso a datos
- Cache-Aside: Cache inteligente con invalidaci√≥n
- Observer: Notificaciones de cambios de datos
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum
import json
import sqlite3
import threading
import time
import hashlib
import pickle
import gzip
from pathlib import Path
import pytz

# Importar position management components
from .states import PositionStatus, ExecutionType
from .data_models import EnhancedPosition, ExecutionLevel, PositionSummary
from .state_manager import StateChangeEvent, StateChangeNotification

# Importar database components
from database.connection import get_connection
from database.position_queries import PositionQueries

import config

logger = logging.getLogger(__name__)


class CacheStrategy(Enum):
    """Estrategias de cache"""
    WRITE_THROUGH = "WRITE_THROUGH"      # Escribe a DB y cache simult√°neamente
    WRITE_BACK = "WRITE_BACK"            # Escribe a cache, a DB peri√≥dicamente
    WRITE_AROUND = "WRITE_AROUND"        # Escribe solo a DB, invalida cache


class TransactionStatus(Enum):
    """Estados de transacci√≥n"""
    PENDING = "PENDING"
    COMMITTED = "COMMITTED"
    ROLLED_BACK = "ROLLED_BACK"
    FAILED = "FAILED"


class ConflictResolution(Enum):
    """Estrategias de resoluci√≥n de conflictos"""
    LAST_WRITE_WINS = "LAST_WRITE_WINS"
    MERGE_CHANGES = "MERGE_CHANGES"
    MANUAL_REVIEW = "MANUAL_REVIEW"
    REJECT_CHANGE = "REJECT_CHANGE"


@dataclass
class CacheEntry:
    """Entrada del cache con metadata"""
    key: str
    data: Any
    created_at: datetime = field(default_factory=lambda: datetime.now(pytz.UTC))
    last_accessed: datetime = field(default_factory=lambda: datetime.now(pytz.UTC))
    access_count: int = 0
    hash: str = ""
    expires_at: Optional[datetime] = None
    dirty: bool = False  # True si hay cambios no persistidos
    
    def __post_init__(self):
        """Post-inicializaci√≥n para calcular hash"""
        if not self.hash and self.data:
            self.hash = self._calculate_hash()
    
    def _calculate_hash(self) -> str:
        """Calcular hash de los datos"""
        try:
            serialized = pickle.dumps(self.data)
            return hashlib.md5(serialized).hexdigest()
        except Exception:
            return str(hash(str(self.data)))
    
    def is_expired(self) -> bool:
        """Verificar si la entrada ha expirado"""
        if not self.expires_at:
            return False
        return datetime.now(pytz.UTC) > self.expires_at
    
    def touch(self):
        """Actualizar √∫ltimo acceso"""
        self.last_accessed = datetime.now(pytz.UTC)
        self.access_count += 1


@dataclass
class Transaction:
    """Transacci√≥n de base de datos"""
    transaction_id: str
    operations: List[Dict[str, Any]] = field(default_factory=list)
    status: TransactionStatus = TransactionStatus.PENDING
    started_at: datetime = field(default_factory=lambda: datetime.now(pytz.UTC))
    completed_at: Optional[datetime] = None
    rollback_data: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None


@dataclass
class DataConflict:
    """Conflicto de datos detectado"""
    conflict_id: str
    key: str
    local_data: Any
    remote_data: Any
    local_hash: str
    remote_hash: str
    detected_at: datetime = field(default_factory=lambda: datetime.now(pytz.UTC))
    resolution_strategy: ConflictResolution = ConflictResolution.LAST_WRITE_WINS
    resolved: bool = False


class PersistenceManager:
    """
    Manager principal para persistencia y cache
    """
    
    def __init__(self):
        """Inicializar el persistence manager"""
        self.position_queries = PositionQueries()
        
        # Cache inteligente
        self._cache: Dict[str, CacheEntry] = {}
        self._cache_lock = threading.RLock()
        self.cache_strategy = CacheStrategy.WRITE_THROUGH
        
        # Configuraci√≥n de cache
        self.max_cache_size = getattr(config, 'MAX_CACHE_SIZE', 1000)
        self.default_ttl = timedelta(minutes=getattr(config, 'CACHE_TTL_MINUTES', 30))
        self.cleanup_interval = timedelta(minutes=getattr(config, 'CACHE_CLEANUP_MINUTES', 5))
        
        # Transaction management
        self._active_transactions: Dict[str, Transaction] = {}
        self._transaction_lock = threading.Lock()
        
        # Conflict detection
        self._conflicts: Dict[str, DataConflict] = {}
        self._conflict_callbacks: List[Callable[[DataConflict], None]] = []
        
        # Background tasks
        self._shutdown = False
        self._cleanup_thread = threading.Thread(target=self._cleanup_loop, daemon=True)
        self._sync_thread = threading.Thread(target=self._sync_loop, daemon=True)
        
        # Estad√≠sticas
        self._stats = {
            'cache_hits': 0,
            'cache_misses': 0,
            'cache_evictions': 0,
            'transactions_committed': 0,
            'transactions_rolled_back': 0,
            'conflicts_detected': 0,
            'conflicts_resolved': 0
        }
        
        # Iniciar background tasks
        self._cleanup_thread.start()
        self._sync_thread.start()
        
        logger.info("üíæ Persistence Manager inicializado")
    
    # ==============================================
    # CACHE MANAGEMENT - API PRINCIPAL
    # ==============================================
    
    def get_position(self, position_id: str) -> Optional[EnhancedPosition]:
        """
        Obtener posici√≥n con cache inteligente
        
        Args:
            position_id: ID de la posici√≥n
            
        Returns:
            EnhancedPosition si existe, None si no se encuentra
        """
        cache_key = f"position:{position_id}"
        
        # Intentar cache primero
        cached_position = self._get_from_cache(cache_key)
        if cached_position:
            self._stats['cache_hits'] += 1
            return cached_position
        
        # Cache miss - cargar desde DB
        self._stats['cache_misses'] += 1
        
        try:
            position = self.position_queries.get_position_by_id(position_id)
            
            if position:
                # Guardar en cache
                self._put_in_cache(cache_key, position, ttl=self.default_ttl)
                logger.debug(f"üíæ Posici√≥n cargada desde DB y cacheada: {position_id}")
            
            return position
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando posici√≥n {position_id}: {e}")
            return None
    
    def save_position(self, position: EnhancedPosition, 
                     transaction_id: Optional[str] = None) -> bool:
        """
        Guardar posici√≥n con estrategia de cache configurada
        
        Args:
            position: Posici√≥n a guardar
            transaction_id: ID de transacci√≥n (opcional)
            
        Returns:
            True si se guard√≥ exitosamente
        """
        cache_key = f"position:{position.position_id}"
        
        try:
            # Detectar conflictos si ya existe
            existing_position = self._get_from_cache(cache_key)
            if existing_position and self._detect_conflict(position, existing_position):
                conflict = self._handle_data_conflict(cache_key, position, existing_position)
                if not conflict.resolved:
                    logger.warning(f"‚ö†Ô∏è Conflicto no resuelto para {position.position_id}")
                    return False
            
            # Guardar seg√∫n estrategia
            if self.cache_strategy == CacheStrategy.WRITE_THROUGH:
                success = self._write_through(cache_key, position, transaction_id)
            elif self.cache_strategy == CacheStrategy.WRITE_BACK:
                success = self._write_back(cache_key, position)
            else:  # WRITE_AROUND
                success = self._write_around(cache_key, position, transaction_id)
            
            if success:
                logger.debug(f"üíæ Posici√≥n guardada: {position.position_id}")
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Error guardando posici√≥n {position.position_id}: {e}")
            return False
    
    def delete_position(self, position_id: str, 
                       transaction_id: Optional[str] = None) -> bool:
        """
        Eliminar posici√≥n del cache y base de datos
        
        Args:
            position_id: ID de la posici√≥n
            transaction_id: ID de transacci√≥n (opcional)
            
        Returns:
            True si se elimin√≥ exitosamente
        """
        cache_key = f"position:{position_id}"
        
        try:
            # Eliminar de cache
            self._remove_from_cache(cache_key)
            
            # Eliminar de base de datos
            # (Implementaci√≥n simplificada - en realidad marcar√≠amos como eliminado)
            success = True  # self.position_queries.delete_position(position_id)
            
            if success:
                logger.info(f"üóëÔ∏è Posici√≥n eliminada: {position_id}")
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Error eliminando posici√≥n {position_id}: {e}")
            return False
    
    def invalidate_cache(self, pattern: Optional[str] = None):
        """
        Invalidar entradas del cache
        
        Args:
            pattern: Patr√≥n para invalidar (None = invalidar todo)
        """
        with self._cache_lock:
            if pattern:
                keys_to_remove = [key for key in self._cache.keys() if pattern in key]
                for key in keys_to_remove:
                    del self._cache[key]
                    self._stats['cache_evictions'] += 1
                logger.info(f"üßπ Cache invalidado: {len(keys_to_remove)} entradas con patr√≥n '{pattern}'")
            else:
                count = len(self._cache)
                self._cache.clear()
                self._stats['cache_evictions'] += count
                logger.info(f"üßπ Cache completamente invalidado: {count} entradas")
    
    # ==============================================
    # TRANSACTION MANAGEMENT
    # ==============================================
    
    def begin_transaction(self) -> str:
        """
        Iniciar una nueva transacci√≥n
        
        Returns:
            transaction_id: ID √∫nico de la transacci√≥n
        """
        transaction_id = f"txn_{int(time.time())}_{threading.get_ident()}"
        
        with self._transaction_lock:
            transaction = Transaction(transaction_id=transaction_id)
            self._active_transactions[transaction_id] = transaction
        
        logger.debug(f"üîÑ Transacci√≥n iniciada: {transaction_id}")
        return transaction_id
    
    def commit_transaction(self, transaction_id: str) -> bool:
        """
        Confirmar transacci√≥n
        
        Args:
            transaction_id: ID de la transacci√≥n
            
        Returns:
            True si se confirm√≥ exitosamente
        """
        with self._transaction_lock:
            transaction = self._active_transactions.get(transaction_id)
            if not transaction:
                logger.warning(f"‚ö†Ô∏è Transacci√≥n no encontrada: {transaction_id}")
                return False
            
            try:
                # Ejecutar todas las operaciones
                conn = get_connection()
                conn.execute("BEGIN TRANSACTION")
                
                for operation in transaction.operations:
                    self._execute_operation(conn, operation)
                
                conn.commit()
                conn.close()
                
                # Marcar como confirmada
                transaction.status = TransactionStatus.COMMITTED
                transaction.completed_at = datetime.now(pytz.UTC)
                
                self._stats['transactions_committed'] += 1
                logger.debug(f"‚úÖ Transacci√≥n confirmada: {transaction_id}")
                return True
                
            except Exception as e:
                # Rollback autom√°tico
                conn.rollback()
                conn.close()
                
                transaction.status = TransactionStatus.FAILED
                transaction.error_message = str(e)
                transaction.completed_at = datetime.now(pytz.UTC)
                
                logger.error(f"‚ùå Error en transacci√≥n {transaction_id}: {e}")
                return self.rollback_transaction(transaction_id)
            
            finally:
                # Limpiar transacci√≥n activa
                del self._active_transactions[transaction_id]
    
    def rollback_transaction(self, transaction_id: str) -> bool:
        """
        Revertir transacci√≥n
        
        Args:
            transaction_id: ID de la transacci√≥n
            
        Returns:
            True si se revirti√≥ exitosamente
        """
        with self._transaction_lock:
            transaction = self._active_transactions.get(transaction_id)
            if not transaction:
                logger.warning(f"‚ö†Ô∏è Transacci√≥n no encontrada para rollback: {transaction_id}")
                return False
            
            try:
                # Revertir operaciones usando rollback_data
                for operation_id, rollback_info in transaction.rollback_data.items():
                    self._revert_operation(rollback_info)
                
                transaction.status = TransactionStatus.ROLLED_BACK
                transaction.completed_at = datetime.now(pytz.UTC)
                
                self._stats['transactions_rolled_back'] += 1
                logger.info(f"üîÑ Transacci√≥n revertida: {transaction_id}")
                return True
                
            except Exception as e:
                logger.error(f"‚ùå Error en rollback {transaction_id}: {e}")
                return False
            
            finally:
                # Limpiar transacci√≥n activa
                if transaction_id in self._active_transactions:
                    del self._active_transactions[transaction_id]
    
    # ==============================================
    # CONFLICT DETECTION Y RESOLUTION
    # ==============================================
    
    def _detect_conflict(self, new_data: Any, existing_data: Any) -> bool:
        """Detectar si hay conflicto entre datos"""
        try:
            if not existing_data:
                return False
            
            # Comparar timestamps de actualizaci√≥n
            if hasattr(new_data, 'updated_at') and hasattr(existing_data, 'updated_at'):
                if new_data.updated_at and existing_data.updated_at:
                    time_diff = abs((new_data.updated_at - existing_data.updated_at).total_seconds())
                    # Si ambas actualizaciones est√°n muy cerca, puede ser conflicto
                    if time_diff < 10:  # 10 segundos
                        return True
            
            # Comparar hashes de contenido
            new_hash = hashlib.md5(str(new_data).encode()).hexdigest()
            existing_hash = hashlib.md5(str(existing_data).encode()).hexdigest()
            
            return new_hash != existing_hash
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error detectando conflicto: {e}")
            return False
    
    def _handle_data_conflict(self, key: str, local_data: Any, 
                             remote_data: Any) -> DataConflict:
        """Manejar conflicto de datos detectado"""
        conflict_id = f"conflict_{int(time.time())}_{abs(hash(key))}"
        
        conflict = DataConflict(
            conflict_id=conflict_id,
            key=key,
            local_data=local_data,
            remote_data=remote_data,
            local_hash=hashlib.md5(str(local_data).encode()).hexdigest(),
            remote_hash=hashlib.md5(str(remote_data).encode()).hexdigest()
        )
        
        # Resolver seg√∫n estrategia
        if conflict.resolution_strategy == ConflictResolution.LAST_WRITE_WINS:
            # Usar los datos con timestamp m√°s reciente
            if hasattr(local_data, 'updated_at') and hasattr(remote_data, 'updated_at'):
                if local_data.updated_at and remote_data.updated_at:
                    if local_data.updated_at > remote_data.updated_at:
                        # Local data wins
                        conflict.resolved = True
                        logger.info(f"üîÑ Conflicto resuelto - Local data wins: {conflict_id}")
                    else:
                        # Remote data wins - actualizar con datos remotos
                        conflict.resolved = True
                        logger.info(f"üîÑ Conflicto resuelto - Remote data wins: {conflict_id}")
        
        self._conflicts[conflict_id] = conflict
        self._stats['conflicts_detected'] += 1
        
        # Notificar callbacks
        for callback in self._conflict_callbacks:
            try:
                callback(conflict)
            except Exception as e:
                logger.error(f"‚ùå Error en conflict callback: {e}")
        
        return conflict
    
    # ==============================================
    # M√âTODOS PRIVADOS - CACHE OPERATIONS
    # ==============================================
    
    def _get_from_cache(self, key: str) -> Optional[Any]:
        """Obtener desde cache con validaci√≥n"""
        with self._cache_lock:
            entry = self._cache.get(key)
            if not entry:
                return None
            
            # Verificar expiraci√≥n
            if entry.is_expired():
                del self._cache[key]
                self._stats['cache_evictions'] += 1
                return None
            
            # Actualizar acceso
            entry.touch()
            return entry.data
    
    def _put_in_cache(self, key: str, data: Any, ttl: Optional[timedelta] = None):
        """Guardar en cache con TTL"""
        with self._cache_lock:
            # Verificar l√≠mite de cache
            if len(self._cache) >= self.max_cache_size:
                self._evict_lru_entries(1)
            
            expires_at = None
            if ttl:
                expires_at = datetime.now(pytz.UTC) + ttl
            
            entry = CacheEntry(
                key=key,
                data=data,
                expires_at=expires_at
            )
            
            self._cache[key] = entry
    
    def _remove_from_cache(self, key: str):
        """Remover del cache"""
        with self._cache_lock:
            if key in self._cache:
                del self._cache[key]
                self._stats['cache_evictions'] += 1
    
    def _evict_lru_entries(self, count: int):
        """Evict entries menos recientemente usadas"""
        if not self._cache:
            return
        
        # Ordenar por √∫ltimo acceso
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: x[1].last_accessed
        )
        
        for i in range(min(count, len(sorted_entries))):
            key = sorted_entries[i][0]
            del self._cache[key]
            self._stats['cache_evictions'] += 1
    
    # ==============================================
    # M√âTODOS PRIVADOS - PERSISTENCE STRATEGIES
    # ==============================================
    
    def _write_through(self, key: str, data: Any, transaction_id: Optional[str] = None) -> bool:
        """Write-through: escribir a DB y cache simult√°neamente"""
        try:
            # Escribir a base de datos primero
            success = self._persist_to_database(data, transaction_id)
            
            if success:
                # Actualizar cache solo si DB fue exitosa
                self._put_in_cache(key, data, ttl=self.default_ttl)
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Error en write-through {key}: {e}")
            return False
    
    def _write_back(self, key: str, data: Any) -> bool:
        """Write-back: escribir a cache, DB peri√≥dicamente"""
        try:
            # Escribir a cache inmediatamente
            entry = CacheEntry(
                key=key,
                data=data,
                dirty=True,  # Marcar como pendiente de sincronizaci√≥n
                expires_at=datetime.now(pytz.UTC) + self.default_ttl
            )
            
            with self._cache_lock:
                self._cache[key] = entry
            
            # La sincronizaci√≥n a DB se hace en background
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en write-back {key}: {e}")
            return False
    
    def _write_around(self, key: str, data: Any, transaction_id: Optional[str] = None) -> bool:
        """Write-around: escribir solo a DB, invalidar cache"""
        try:
            # Escribir solo a base de datos
            success = self._persist_to_database(data, transaction_id)
            
            if success:
                # Invalidar cache entry si existe
                self._remove_from_cache(key)
            
            return success
            
        except Exception as e:
            logger.error(f"‚ùå Error en write-around {key}: {e}")
            return False
    
    def _persist_to_database(self, data: Any, transaction_id: Optional[str] = None) -> bool:
        """Persistir datos a base de datos"""
        try:
            if isinstance(data, EnhancedPosition):
                # Guardar posici√≥n usando position_queries
                return self._save_position_to_db(data)
            else:
                logger.warning(f"‚ö†Ô∏è Tipo de dato no soportado para persistencia: {type(data)}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error persistiendo a DB: {e}")
            return False
    
    def _save_position_to_db(self, position: EnhancedPosition) -> bool:
        """Guardar posici√≥n espec√≠ficamente"""
        try:
            # Convertir niveles a datos de ejecuci√≥n para DB
            for level in position.entry_levels + position.exit_levels:
                if level.executed_at:  # Solo guardar niveles ejecutados
                    execution_data = {
                        'symbol': position.symbol,
                        'position_id': position.position_id,
                        'level_id': str(level.level_id),
                        'execution_type': level.level_type.value,
                        'status': 'FILLED' if level.executed_price else 'PENDING',
                        'target_price': level.target_price,
                        'executed_price': level.executed_price,
                        'quantity': level.quantity,
                        'percentage': level.percentage,
                        'created_at': level.created_at.isoformat(),
                        'executed_at': level.executed_at.isoformat() if level.executed_at else None,
                        'description': level.description
                    }
            
            # Serializar datos del cache
            with self._cache_lock:
                for key, entry in self._cache.items():
                    if not entry.is_expired():
                        snapshot_data['cache_data'][key] = {
                            'data': entry.data,
                            'created_at': entry.created_at.isoformat(),
                            'hash': entry.hash,
                            'access_count': entry.access_count
                        }
            
            # Comprimir y guardar
            with gzip.open(backup_file, 'wb') as f:
                pickle.dump(snapshot_data, f)
            
            logger.info(f"üì∏ Snapshot creado: {backup_file}")
            return backup_file
            
        except Exception as e:
            logger.error(f"‚ùå Error creando snapshot: {e}")
            raise
    
    def restore_snapshot(self, backup_file: str) -> bool:
        """Restaurar desde snapshot"""
        try:
            if not Path(backup_file).exists():
                logger.error(f"‚ùå Archivo de backup no encontrado: {backup_file}")
                return False
            
            with gzip.open(backup_file, 'rb') as f:
                snapshot_data = pickle.load(f)
            
            # Restaurar cache
            with self._cache_lock:
                self._cache.clear()
                
                for key, entry_data in snapshot_data['cache_data'].items():
                    entry = CacheEntry(
                        key=key,
                        data=entry_data['data'],
                        created_at=datetime.fromisoformat(entry_data['created_at']),
                        hash=entry_data['hash'],
                        access_count=entry_data['access_count']
                    )
                    self._cache[key] = entry
            
            logger.info(f"üì• Snapshot restaurado: {backup_file}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error restaurando snapshot {backup_file}: {e}")
            return False
    
    # ==============================================
    # BATCH OPERATIONS
    # ==============================================
    
    def batch_save_positions(self, positions: List[EnhancedPosition]) -> Dict[str, bool]:
        """
        Guardar m√∫ltiples posiciones en batch
        
        Args:
            positions: Lista de posiciones a guardar
            
        Returns:
            Dict con resultado por position_id
        """
        results = {}
        transaction_id = self.begin_transaction()
        
        try:
            for position in positions:
                success = self.save_position(position, transaction_id)
                results[position.position_id] = success
            
            # Si todas fueron exitosas, commit
            all_success = all(results.values())
            if all_success:
                self.commit_transaction(transaction_id)
                logger.info(f"üíæ Batch save exitoso: {len(positions)} posiciones")
            else:
                self.rollback_transaction(transaction_id)
                logger.warning(f"‚ö†Ô∏è Batch save fall√≥, rollback ejecutado")
            
            return results
            
        except Exception as e:
            self.rollback_transaction(transaction_id)
            logger.error(f"‚ùå Error en batch save: {e}")
            return {pos.position_id: False for pos in positions}
    
    def batch_get_positions(self, position_ids: List[str]) -> Dict[str, Optional[EnhancedPosition]]:
        """
        Obtener m√∫ltiples posiciones en batch
        
        Args:
            position_ids: Lista de IDs de posiciones
            
        Returns:
            Dict con posiciones encontradas
        """
        results = {}
        
        for position_id in position_ids:
            results[position_id] = self.get_position(position_id)
        
        return results
    
    # ==============================================
    # OBSERVERS Y CALLBACKS
    # ==============================================
    
    def add_conflict_callback(self, callback: Callable[[DataConflict], None]):
        """A√±adir callback para conflictos de datos"""
        self._conflict_callbacks.append(callback)
    
    def remove_conflict_callback(self, callback: Callable[[DataConflict], None]):
        """Remover callback espec√≠fico"""
        if callback in self._conflict_callbacks:
            self._conflict_callbacks.remove(callback)
    
    # ==============================================
    # CLEANUP Y SHUTDOWN
    # ==============================================
    
    def flush_dirty_entries(self) -> int:
        """Forzar sincronizaci√≥n de entradas dirty"""
        dirty_count = 0
        
        with self._cache_lock:
            for key, entry in self._cache.items():
                if entry.dirty:
                    try:
                        success = self._persist_to_database(entry.data)
                        if success:
                            entry.dirty = False
                            dirty_count += 1
                    except Exception as e:
                        logger.error(f"‚ùå Error sincronizando entrada dirty {key}: {e}")
        
        logger.info(f"üíæ Flush completado: {dirty_count} entradas sincronizadas")
        return dirty_count
    
    def shutdown(self):
        """Shutdown limpio del persistence manager"""
        logger.info("üõë Iniciando shutdown del Persistence Manager...")
        
        self._shutdown = True
        
        # Flush entradas dirty
        self.flush_dirty_entries()
        
        # Commit transacciones pendientes o rollback
        with self._transaction_lock:
            for transaction_id in list(self._active_transactions.keys()):
                if self._active_transactions[transaction_id].status == TransactionStatus.PENDING:
                    logger.warning(f"‚ö†Ô∏è Transacci√≥n pendiente durante shutdown, haciendo rollback: {transaction_id}")
                    self.rollback_transaction(transaction_id)
        
        # Esperar que terminen threads de background
        if self._cleanup_thread.is_alive():
            self._cleanup_thread.join(timeout=5)
        
        if self._sync_thread.is_alive():
            self._sync_thread.join(timeout=5)
        
        logger.info("‚úÖ Persistence Manager cerrado correctamente")


# ==============================================
# FACTORY Y SINGLETON PATTERN
# ==============================================

_persistence_manager_instance: Optional[PersistenceManager] = None

def get_persistence_manager() -> PersistenceManager:
    """
    Obtener instancia singleton del PersistenceManager
    
    Returns:
        Instancia √∫nica del PersistenceManager
    """
    global _persistence_manager_instance
    
    if _persistence_manager_instance is None:
        _persistence_manager_instance = PersistenceManager()
    
    return _persistence_manager_instance


def reset_persistence_manager():
    """Resetear instancia del PersistenceManager (√∫til para testing)"""
    global _persistence_manager_instance
    if _persistence_manager_instance:
        _persistence_manager_instance.shutdown()
    _persistence_manager_instance = None


# ==============================================
# UTILITIES Y HELPERS
# ==============================================

def calculate_cache_efficiency(stats: Dict[str, Any]) -> float:
    """Calcular eficiencia del cache"""
    total_requests = stats.get('cache_hits', 0) + stats.get('cache_misses', 0)
    if total_requests == 0:
        return 0.0
    
    return (stats.get('cache_hits', 0) / total_requests) * 100


def format_cache_size(size_bytes: int) -> str:
    """Formatear tama√±o del cache en formato legible"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} TB"


# ==============================================
# TESTING Y DEMO
# ==============================================

if __name__ == "__main__":
    # Demo del persistence manager
    print("üíæ PERSISTENCE MANAGER - Demo")
    print("=" * 50)
    
    manager = get_persistence_manager()
    
    # Crear posici√≥n de prueba
    from .data_models import EnhancedPosition
    from .states import SignalDirection
    
    test_position = EnhancedPosition(
        symbol="DEMO",
        direction=SignalDirection.LONG,
        position_id="DEMO_001"
    )
    
    # Guardar posici√≥n
    print("üíæ Guardando posici√≥n...")
    success = manager.save_position(test_position)
    print(f"Resultado: {'‚úÖ Exitoso' if success else '‚ùå Error'}")
    
    # Obtener posici√≥n (deber√≠a venir del cache)
    print("\nüìä Obteniendo posici√≥n...")
    retrieved_position = manager.get_position("DEMO_001")
    print(f"Resultado: {'‚úÖ Encontrada' if retrieved_position else '‚ùå No encontrada'}")
    
    # Estad√≠sticas del cache
    print("\nüìà Estad√≠sticas del cache:")
    stats = manager.get_cache_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # Estado de salud
    health = manager.get_health_status()
    print(f"\nüè• Estado de salud: {health}")
    
    # Crear snapshot
    print("\nüì∏ Creando snapshot...")
    backup_file = manager.create_snapshot()
    print(f"Snapshot creado: {backup_file}")
    
    print("\nüèÅ Demo completado")
    
    # Cleanup
    manager.shutdown()
    
    # ==============================================
    # BACKGROUND TASKS
    # ==============================================
    
    def _cleanup_loop(self):
        """Loop de limpieza en background"""
        while not self._shutdown:
            try:
                time.sleep(self.cleanup_interval.total_seconds())
                
                if self._shutdown:
                    break
                
                # Limpiar entradas expiradas
                expired_keys = []
                with self._cache_lock:
                    for key, entry in self._cache.items():
                        if entry.is_expired():
                            expired_keys.append(key)
                
                if expired_keys:
                    with self._cache_lock:
                        for key in expired_keys:
                            if key in self._cache:
                                del self._cache[key]
                                self._stats['cache_evictions'] += 1
                    
                    logger.debug(f"üßπ Limpiadas {len(expired_keys)} entradas expiradas del cache")
                
                # Limpiar transacciones antiguas
                self._cleanup_old_transactions()
                
            except Exception as e:
                logger.error(f"‚ùå Error en cleanup loop: {e}")
    
    def _sync_loop(self):
        """Loop de sincronizaci√≥n en background"""
        while not self._shutdown:
            try:
                time.sleep(30)  # Sincronizar cada 30 segundos
                
                if self._shutdown:
                    break
                
                # Sincronizar entradas dirty (write-back)
                dirty_entries = []
                with self._cache_lock:
                    for key, entry in self._cache.items():
                        if entry.dirty:
                            dirty_entries.append((key, entry))
                
                for key, entry in dirty_entries:
                    try:
                        success = self._persist_to_database(entry.data)
                        if success:
                            entry.dirty = False
                            logger.debug(f"üíæ Sincronizada entrada dirty: {key}")
                    except Exception as e:
                        logger.error(f"‚ùå Error sincronizando {key}: {e}")
                
            except Exception as e:
                logger.error(f"‚ùå Error en sync loop: {e}")
    
    def _cleanup_old_transactions(self):
        """Limpiar transacciones antigas"""
        cutoff_time = datetime.now(pytz.UTC) - timedelta(hours=1)
        
        with self._transaction_lock:
            old_transactions = [
                tid for tid, txn in self._active_transactions.items()
                if txn.started_at < cutoff_time and txn.status == TransactionStatus.PENDING
            ]
            
            for tid in old_transactions:
                logger.warning(f"‚ö†Ô∏è Transacci√≥n antigua detectada, forzando rollback: {tid}")
                self.rollback_transaction(tid)
    
    def _execute_operation(self, conn: sqlite3.Connection, operation: Dict[str, Any]):
        """Ejecutar operaci√≥n de base de datos"""
        op_type = operation.get('type')
        
        if op_type == 'INSERT':
            conn.execute(operation['sql'], operation['params'])
        elif op_type == 'UPDATE':
            conn.execute(operation['sql'], operation['params'])
        elif op_type == 'DELETE':
            conn.execute(operation['sql'], operation['params'])
        else:
            raise ValueError(f"Tipo de operaci√≥n no soportado: {op_type}")
    
    def _revert_operation(self, rollback_info: Dict[str, Any]):
        """Revertir operaci√≥n usando informaci√≥n de rollback"""
        # Implementaci√≥n simplificada
        logger.debug(f"üîÑ Revirtiendo operaci√≥n: {rollback_info}")
    
    # ==============================================
    # ESTAD√çSTICAS Y MONITORING
    # ==============================================
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas del cache"""
        with self._cache_lock:
            cache_size = len(self._cache)
            dirty_count = sum(1 for entry in self._cache.values() if entry.dirty)
            
            total_requests = self._stats['cache_hits'] + self._stats['cache_misses']
            hit_rate = (self._stats['cache_hits'] / total_requests * 100) if total_requests > 0 else 0
        
        return {
            **self._stats,
            'cache_size': cache_size,
            'dirty_entries': dirty_count,
            'cache_hit_rate': hit_rate,
            'max_cache_size': self.max_cache_size,
            'active_transactions': len(self._active_transactions),
            'unresolved_conflicts': len([c for c in self._conflicts.values() if not c.resolved])
        }
    
    def get_health_status(self) -> str:
        """Obtener estado de salud del sistema"""
        stats = self.get_cache_stats()
        
        if stats['cache_hit_rate'] > 80 and stats['unresolved_conflicts'] == 0:
            return "HEALTHY"
        elif stats['cache_hit_rate'] > 60 and stats['unresolved_conflicts'] < 5:
            return "DEGRADED"
        else:
            return "UNHEALTHY"
    
    # ==============================================
    # BACKUP Y RECOVERY
    # ==============================================
    
    def create_snapshot(self, backup_path: Optional[str] = None) -> str:
        """Crear snapshot de datos cr√≠ticos"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = backup_path or f"position_snapshot_{timestamp}.gz"
        
        try:
            snapshot_data = {
                'timestamp': timestamp,
                'cache_data': {},
                'metadata': {
                    'cache_size': len(self._cache),
                    'stats': self._stats.copy()
                }