#!/usr/bin/env python3
"""
ğŸ“Š SMART ENHANCEMENTS - MEJORAS AVANZADAS PARA EL SISTEMA DE TRADING
==================================================================

Este archivo contiene 4 mejoras principales:

1. ğŸ›¡ï¸ RATE LIMIT MANAGER - Evita exceder lÃ­mites de Yahoo Finance
2. ğŸ’¾ DATA CACHE - Reduce requests repetidos en 70-80%
3. ğŸ”„ ERROR RECOVERY - Retry automÃ¡tico con backoff exponencial  
4. ğŸ“ˆ PERFORMANCE MONITOR - MÃ©tricas detalladas del sistema

Â¿QUÃ‰ HACEN ESTAS MEJORAS?
=========================

ğŸ›¡ï¸ RATE LIMIT MANAGER:
- Cuenta cuÃ¡ntos requests haces por hora
- Te avisa si te acercas al lÃ­mite
- Fuerza delays entre requests (mÃ­nimo 2 segundos)
- Evita los errores "429 Too Many Requests"

ğŸ’¾ DATA CACHE:
- Guarda datos descargados por 5 minutos
- Si pides los mismos datos, los sirve del cache
- Reduce 70-80% los requests reales a Yahoo Finance
- Cache en memoria + disco para persistencia

ğŸ”„ ERROR RECOVERY:
- Si Yahoo da error, reintenta automÃ¡ticamente
- Backoff exponencial: 1s, 2s, 4s, 8s...
- Estrategias especÃ­ficas por tipo de error
- Historial de errores para diagnÃ³stico

ğŸ“ˆ PERFORMANCE MONITOR:
- Mide tiempo de cada funciÃ³n
- Cuenta Ã©xitos/fallos
- Genera reportes de rendimiento
- Te dice quÃ© funciones son lentas
"""

import time
import hashlib
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import pickle
import os
import logging

logger = logging.getLogger(__name__)

class RateLimitManager:
    """
    ğŸ›¡ï¸ RATE LIMIT MANAGER
    
    Â¿QUÃ‰ HACE?
    - Evita que hagas demasiados requests muy rÃ¡pido
    - Yahoo Finance bloquea IPs que hacen muchas peticiones
    - Este manager te protege automÃ¡ticamente
    
    EJEMPLO:
    - Sin manager: 100 requests en 1 minuto â†’ BLOQUEADO âŒ
    - Con manager: 100 requests en 1 hora â†’ TODO OK âœ…
    """
    
    def __init__(self, requests_per_hour: int = 80):
        self.requests_per_hour = requests_per_hour
        self.request_log = []  # Timestamps de requests
        self.last_request_time = None
        self.min_delay_seconds = 2  # MÃ­nimo delay entre requests
        
        logger.info(f"ğŸ›¡ï¸ Rate Limiter: mÃ¡ximo {requests_per_hour} requests/hora")
    
    def can_make_request(self) -> bool:
        """Â¿Puedo hacer un request sin ser bloqueado?"""
        try:
            now = datetime.now()
            
            # Limpiar requests antiguos (>1 hora)
            one_hour_ago = now - timedelta(hours=1)
            self.request_log = [t for t in self.request_log if t > one_hour_ago]
            
            # Â¿He hecho demasiados requests esta hora?
            if len(self.request_log) >= self.requests_per_hour:
                logger.warning(f"âš ï¸ Rate limit: {len(self.request_log)}/{self.requests_per_hour} requests/hora")
                return False
            
            # Â¿Ha pasado suficiente tiempo desde el Ãºltimo request?
            if self.last_request_time:
                seconds_since_last = (now - self.last_request_time).total_seconds()
                if seconds_since_last < self.min_delay_seconds:
                    return False
            
            return True
        except Exception as e:
            logger.error(f"âŒ Error en rate limit check: {e}")
            return True  # Si hay error, permitir request
    
    def wait_if_needed(self):
        """Esperar automÃ¡ticamente si es necesario"""
        try:
            while not self.can_make_request():
                # Calcular cuÃ¡nto esperar
                if self.last_request_time:
                    seconds_since = (datetime.now() - self.last_request_time).total_seconds()
                    wait_time = max(0, self.min_delay_seconds - seconds_since)
                    
                    if wait_time > 0:
                        logger.info(f"â³ Rate limit: esperando {wait_time:.1f}s...")
                        time.sleep(wait_time)
                    else:
                        # LÃ­mite por hora alcanzado
                        logger.info("â³ Rate limit por hora - esperando 60s...")
                        time.sleep(60)
                else:
                    time.sleep(self.min_delay_seconds)
        except Exception as e:
            logger.error(f"âŒ Error en wait: {e}")
    
    def log_request(self):
        """Registrar que hice un request"""
        now = datetime.now()
        self.request_log.append(now)
        self.last_request_time = now
        
        logger.debug(f"ğŸ“Š Request #{len(self.request_log)} registrado")
    
    def get_stats(self) -> Dict:
        """EstadÃ­sticas del rate limiter"""
        try:
            # Limpiar log primero
            one_hour_ago = datetime.now() - timedelta(hours=1)
            self.request_log = [t for t in self.request_log if t > one_hour_ago]
            
            usage_pct = (len(self.request_log) / self.requests_per_hour) * 100
            
            return {
                'requests_last_hour': len(self.request_log),
                'max_requests_per_hour': self.requests_per_hour,
                'usage_percentage': f"{usage_pct:.1f}%",
                'can_make_request': self.can_make_request(),
                'last_request': self.last_request_time.strftime("%H:%M:%S") if self.last_request_time else "Nunca"
            }
        except Exception as e:
            logger.error(f"âŒ Error en stats: {e}")
            return {}


class DataCache:
    """
    ğŸ’¾ DATA CACHE
    
    Â¿QUÃ‰ HACE?
    - Guarda datos descargados para reutilizarlos
    - Si pides datos de AAPL que descargaste hace 3 minutos, 
      te los da del cache en lugar de descargarlos otra vez
    - Reduce MUCHÃSIMO los requests a Yahoo Finance
    
    EJEMPLO:
    - Sin cache: Escaneo â†’ 9 requests (uno por sÃ­mbolo)
    - Con cache: Escaneo â†’ 0 requests (todo del cache) âœ¨
    """
    
    def __init__(self, cache_dir: str = "./cache", ttl_seconds: int = 300):
        self.cache_dir = cache_dir
        self.ttl_seconds = ttl_seconds  # 5 minutos por defecto
        self.memory_cache = {}
        
        # Crear directorio
        os.makedirs(cache_dir, exist_ok=True)
        
        logger.info(f"ğŸ’¾ Cache inicializado: {cache_dir} (TTL: {ttl_seconds}s)")
    
    def _make_key(self, symbol: str, timeframe: str, **kwargs) -> str:
        """Crear clave Ãºnica para el cache"""
        key_data = f"{symbol}_{timeframe}_{str(sorted(kwargs.items()))}"
        return hashlib.md5(key_data.encode()).hexdigest()[:16]
    
    def get(self, symbol: str, timeframe: str, **kwargs) -> Optional[Any]:
        """Â¿Tengo estos datos en cache?"""
        try:
            key = self._make_key(symbol, timeframe, **kwargs)
            
            # Buscar en memoria primero (mÃ¡s rÃ¡pido)
            if key in self.memory_cache:
                data, timestamp = self.memory_cache[key]
                
                # Â¿Sigue siendo vÃ¡lido?
                if time.time() - timestamp < self.ttl_seconds:
                    logger.debug(f"ğŸ’¾ Cache HIT (memoria): {symbol}")
                    return data
                else:
                    # Expirado - eliminar
                    del self.memory_cache[key]
            
            # Buscar en disco
            cache_file = os.path.join(self.cache_dir, f"{key}.pkl")
            
            if os.path.exists(cache_file):
                file_age = time.time() - os.path.getmtime(cache_file)
                
                if file_age < self.ttl_seconds:
                    # Cargar del disco
                    with open(cache_file, 'rb') as f:
                        data = pickle.load(f)
                    
                    # Guardar en memoria tambiÃ©n
                    self.memory_cache[key] = (data, time.time())
                    
                    logger.debug(f"ğŸ’¾ Cache HIT (disco): {symbol}")
                    return data
                else:
                    # Archivo expirado
                    os.remove(cache_file)
            
            logger.debug(f"ğŸ’¾ Cache MISS: {symbol}")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Error obteniendo cache: {e}")
            return None
    
    def set(self, symbol: str, timeframe: str, data: Any, **kwargs) -> bool:
        """Guardar datos en cache"""
        try:
            key = self._make_key(symbol, timeframe, **kwargs)
            
            # Guardar en memoria
            self.memory_cache[key] = (data, time.time())
            
            # Guardar en disco
            cache_file = os.path.join(self.cache_dir, f"{key}.pkl")
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
            
            logger.debug(f"ğŸ’¾ Cache SAVED: {symbol}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error guardando cache: {e}")
            return False
    
    def get_stats(self) -> Dict:
        """EstadÃ­sticas del cache"""
        try:
            memory_entries = len(self.memory_cache)
            
            disk_entries = 0
            total_size = 0
            
            if os.path.exists(self.cache_dir):
                for filename in os.listdir(self.cache_dir):
                    if filename.endswith('.pkl'):
                        filepath = os.path.join(self.cache_dir, filename)
                        disk_entries += 1
                        total_size += os.path.getsize(filepath)
            
            return {
                'memory_entries': memory_entries,
                'disk_entries': disk_entries,
                'total_entries': memory_entries + disk_entries,
                'cache_size_mb': f"{total_size / (1024*1024):.2f}",
                'ttl_seconds': self.ttl_seconds,
                'hit_rate': "Se calcularÃ¡ en uso real"
            }
        except Exception as e:
            logger.error(f"âŒ Error en cache stats: {e}")
            return {}


class ErrorRecovery:
    """
    ğŸ”„ ERROR RECOVERY
    
    Â¿QUÃ‰ HACE?
    - Si Yahoo Finance da error, reintenta automÃ¡ticamente
    - No te rindes al primer error
    - Backoff exponencial: espera mÃ¡s tiempo entre intentos
    - Estrategias especÃ­ficas segÃºn el tipo de error
    
    EJEMPLO:
    - Sin recovery: Error â†’ Sistema se para âŒ
    - Con recovery: Error â†’ Espera â†’ Reintenta â†’ Â¡Funciona! âœ…
    """
    
    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
        self.error_history = []
        self.recovery_strategies = {}
        
        logger.info(f"ğŸ”„ Error Recovery: mÃ¡ximo {max_retries} reintentos")
    
    def register_strategy(self, error_type: str, strategy_func):
        """Registrar estrategia para tipo de error especÃ­fico"""
        self.recovery_strategies[error_type] = strategy_func
        logger.info(f"ğŸ”§ Estrategia registrada: {error_type}")
    
    def execute_with_retry(self, func, *args, **kwargs):
        """Ejecutar funciÃ³n con reintentos automÃ¡ticos"""
        last_error = None
        
        for attempt in range(self.max_retries + 1):
            try:
                # Intentar ejecutar funciÃ³n
                result = func(*args, **kwargs)
                
                if attempt > 0:
                    logger.info(f"âœ… Â¡Recovery exitoso en intento #{attempt + 1}!")
                
                return result
                
            except Exception as error:
                last_error = error
                error_type = type(error).__name__
                
                # Registrar error en historial
                self.error_history.append({
                    'timestamp': datetime.now(),
                    'error_type': error_type,
                    'message': str(error),
                    'attempt': attempt + 1,
                    'function': func.__name__ if hasattr(func, '__name__') else 'unknown'
                })
                
                logger.warning(f"âš ï¸ Error intento #{attempt + 1}: {error_type}")
                
                # Â¿Es el Ãºltimo intento?
                if attempt >= self.max_retries:
                    break
                
                # Â¿Hay estrategia especÃ­fica para este error?
                if error_type in self.recovery_strategies:
                    try:
                        logger.info(f"ğŸ”§ Aplicando recovery para {error_type}")
                        self.recovery_strategies[error_type](error)
                    except Exception as recovery_error:
                        logger.error(f"âŒ Error en recovery: {recovery_error}")
                
                # Backoff exponencial: 1s, 2s, 4s, 8s...
                delay = 2 ** attempt
                logger.info(f"â³ Esperando {delay}s antes de reintentar...")
                time.sleep(delay)
        
        # Todos los intentos fallaron
        logger.error(f"ğŸ’¥ FunciÃ³n fallÃ³ despuÃ©s de {self.max_retries + 1} intentos")
        logger.error(f"ğŸ’¥ Ãšltimo error: {last_error}")
        
        return None
    
    def get_stats(self) -> Dict:
        """EstadÃ­sticas de errores"""
        try:
            if not self.error_history:
                return {'total_errors': 0}
            
            # Errores recientes (Ãºltima hora)
            one_hour_ago = datetime.now() - timedelta(hours=1)
            recent = [e for e in self.error_history if e['timestamp'] > one_hour_ago]
            
            # Contar por tipo
            error_types = {}
            for error in recent:
                error_type = error['error_type']
                error_types[error_type] = error_types.get(error_type, 0) + 1
            
            return {
                'total_errors': len(self.error_history),
                'errors_last_hour': len(recent),
                'error_types': error_types,
                'last_error': self.error_history[-1]['error_type'] if self.error_history else None,
                'strategies_registered': len(self.recovery_strategies)
            }
        except Exception as e:
            logger.error(f"âŒ Error en error stats: {e}")
            return {}


class PerformanceMonitor:
    """
    ğŸ“ˆ PERFORMANCE MONITOR
    
    Â¿QUÃ‰ HACE?
    - Mide cuÃ¡nto tarda cada funciÃ³n
    - Cuenta cuÃ¡ntas veces se ejecuta cada funciÃ³n
    - Te dice quÃ© funciones son lentas
    - Genera reportes de rendimiento
    
    EJEMPLO:
    - get_market_data: 47 llamadas, 0.8s promedio, 95% Ã©xito
    - scan_symbol: 423 llamadas, 1.2s promedio, 87% Ã©xito
    """
    
    def __init__(self):
        self.metrics = {}
        self.start_time = datetime.now()
        
        logger.info("ğŸ“ˆ Performance Monitor inicializado")
    
    def record_execution(self, func_name: str, duration: float, success: bool):
        """Registrar ejecuciÃ³n de funciÃ³n"""
        try:
            if func_name not in self.metrics:
                self.metrics[func_name] = {
                    'total_calls': 0,
                    'successful_calls': 0,
                    'total_time': 0.0,
                    'min_time': float('inf'),
                    'max_time': 0.0
                }
            
            metric = self.metrics[func_name]
            metric['total_calls'] += 1
            metric['total_time'] += duration
            metric['min_time'] = min(metric['min_time'], duration)
            metric['max_time'] = max(metric['max_time'], duration)
            
            if success:
                metric['successful_calls'] += 1
                
        except Exception as e:
            logger.error(f"âŒ Error registrando mÃ©trica: {e}")
    
    def get_report(self) -> Dict:
        """Generar reporte de rendimiento"""
        try:
            uptime = datetime.now() - self.start_time
            
            report = {
                'uptime_hours': f"{uptime.total_seconds() / 3600:.1f}h",
                'functions': {}
            }
            
            for func_name, metric in self.metrics.items():
                calls = metric['total_calls']
                successful = metric['successful_calls']
                
                avg_time = metric['total_time'] / calls if calls > 0 else 0
                success_rate = (successful / calls * 100) if calls > 0 else 0
                
                report['functions'][func_name] = {
                    'calls': calls,
                    'success_rate': f"{success_rate:.1f}%",
                    'avg_time': f"{avg_time:.3f}s",
                    'min_time': f"{metric['min_time']:.3f}s" if metric['min_time'] != float('inf') else "0.000s",
                    'max_time': f"{metric['max_time']:.3f}s"
                }
            
            return report
        except Exception as e:
            logger.error(f"âŒ Error en reporte: {e}")
            return {}


def setup_recovery_strategies(error_recovery: ErrorRecovery):
    """Configurar estrategias de recovery"""
    
    def rate_limit_strategy(error):
        """Estrategia para rate limiting"""
        logger.info("ğŸ›¡ï¸ Rate limit detectado - esperando 60s...")
        time.sleep(60)
    
    def network_error_strategy(error):
        """Estrategia para errores de red"""
        logger.info("ğŸŒ Error de red - esperando 30s...")
        time.sleep(30)
    
    def timeout_strategy(error):
        """Estrategia para timeouts"""
        logger.info("â±ï¸ Timeout - esperando 15s...")
        time.sleep(15)
    
    # Registrar estrategias
    error_recovery.register_strategy('YFRateLimitError', rate_limit_strategy)
    error_recovery.register_strategy('ConnectionError', network_error_strategy)
    error_recovery.register_strategy('TimeoutError', timeout_strategy)
    error_recovery.register_strategy('HTTPError', network_error_strategy)


def integrate_smart_features():
    """
    ğŸ¯ FUNCIÃ“N PRINCIPAL - INICIALIZAR TODAS LAS MEJORAS
    
    Esta funciÃ³n crea todos los componentes smart y los devuelve
    para que el main.py los pueda usar.
    """
    logger.info("ğŸš€ Iniciando Smart Features...")
    
    # Crear componentes
    rate_limiter = RateLimitManager(requests_per_hour=80)  # Conservador
    cache = DataCache(cache_dir="./smart_cache", ttl_seconds=300)  # 5 min
    error_recovery = ErrorRecovery(max_retries=3)
    performance = PerformanceMonitor()
    
    # Configurar estrategias de recovery
    setup_recovery_strategies(error_recovery)
    
    def enhanced_market_data_fetch(symbol: str, period: str = "15m", days: int = 30):
        """
        ğŸ¯ FUNCIÃ“N PRINCIPAL MEJORADA
        
        Esta funciÃ³n reemplaza get_market_data() y usa TODAS las mejoras:
        - Primero busca en cache
        - Verifica rate limits
        - Si hay que descargar, lo hace con retry automÃ¡tico
        - Guarda resultado en cache
        """
        
        # 1. Buscar en cache primero
        cached_data = cache.get(symbol, period, days=days)
        if cached_data is not None:
            logger.info(f"ğŸ’¾ Cache HIT: {symbol} (Â¡no download!)")
            return cached_data
        
        logger.info(f"ğŸ’¾ Cache MISS: {symbol} - descargando...")
        
        # 2. FunciÃ³n interna para download
        def download_data():
            # Verificar rate limits
            rate_limiter.wait_if_needed()
            
            # Importar aquÃ­ para evitar circular imports
            from indicators import TechnicalIndicators
            indicators = TechnicalIndicators()
            
            # Registrar request
            rate_limiter.log_request()
            
            # Medir performance
            start_time = time.time()
            success = False
            
            try:
                # Descargar datos
                data = indicators.get_market_data(symbol, period, days)
                success = True
                return data
            finally:
                duration = time.time() - start_time
                performance.record_execution('get_market_data', duration, success)
        
        # 3. Ejecutar download con retry
        data = error_recovery.execute_with_retry(download_data)
        
        # 4. Guardar en cache si exitoso
        if data is not None:
            cache.set(symbol, period, data, days=days)
            logger.info(f"âœ… {symbol} descargado y cacheado")
        else:
            logger.error(f"âŒ {symbol} fallÃ³ definitivamente")
        
        return data
    
    def get_all_stats():
        """Obtener todas las estadÃ­sticas smart"""
        return {
            'rate_limiter': rate_limiter.get_stats(),
            'cache': cache.get_stats(),
            'error_recovery': error_recovery.get_stats(),
            'performance': performance.get_report()
        }
    
    logger.info("âœ… Smart Features inicializados correctamente")
    
    return {
        'rate_limiter': rate_limiter,
        'cache': cache,
        'error_recovery': error_recovery,
        'performance': performance,
        'enhanced_data_fetch': enhanced_market_data_fetch,
        'get_stats': get_all_stats
    }